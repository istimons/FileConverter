{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "17rDr0CL7q7j2XbdoSD713wnp59Ll3Ymx",
      "authorship_tag": "ABX9TyO+Be6XAWJZw2OYLg/UXNnI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/istimons/FileConverter/blob/master/OpenCv%20Images%20%26%20Text%20Detection%20From%20Screenshots%20on%20Colab.\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aP6dbLs_4U4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "2184e711-68e2-4ce6-c898-a6cdc75c08df"
      },
      "source": [
        "# ==================Project Description======================================\n",
        "\"\"\"\n",
        "OpenCv text & image detection in images (From Icons ScreenShots)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# ==================Project Description End==================================\n",
        "\n",
        "\n",
        "\n",
        "# import required libraries \n",
        "\n",
        "# !pip3 install pytesseract\n",
        "# !sudo apt-get install tesseract-ocr-all\n",
        "# !pip install --upgrade pip\n",
        "# !pip install --upgrade google-api-python-client\n",
        "# !pip install --upgrade google-cloud-vision\n",
        "\n",
        "# from google.cloud import vision\n",
        "import pytesseract\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import csv\n",
        "import os\n",
        "import io\n",
        "\n",
        "# Method to detect all labels in images\n",
        "def detect_labels(path):\n",
        "    \"\"\" \n",
        "    This method will detect labels and correspoding confidence score\n",
        "    in each image file.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    # Read the images to get labels\n",
        "    with io.open(path, 'rb') as image_file:\n",
        "        content = image_file.read()\n",
        "    image = vision.types.Image(content=content)\n",
        "    response = client.label_detection(image=image)\n",
        "    labels = response.label_annotations\n",
        "        \n",
        "    print('Labels   |   confidence score')\n",
        "    print('=' * 30, '\\n' )\n",
        "\n",
        "    # Get each label and corresponding image file\n",
        "    for label in response.label_annotations:      \n",
        "      print(label.description, '   =','(%.2f%%)' % (label.score * 100.))\n",
        "\n",
        "\n",
        "# Method to get images from local drive, process them \n",
        "# for text detection & apply detect_label() function\n",
        "def process_all_images(path):\n",
        "  ''' \n",
        "    Loop through images, (to send to detect_labels function)\n",
        "    while retrieving each image text  \n",
        "  '''\n",
        "\n",
        "  image_files = sorted([os.path.join(path, 'images', file)\n",
        "  for file in os.listdir(path + \"/images\")\n",
        "  if file.endswith('.jpg')])\n",
        "\n",
        "  # Loop through each image while reading text\n",
        "  for file in image_files:\n",
        "    print('\\n')\n",
        "    print('Results from image: %s' % file, '\\n' )\n",
        "    print('Text data alignment in this file', '\\n') \n",
        "    \n",
        "    # Grab all detected text from each image File (Tesseract)\n",
        "    # reading image using opencv\n",
        "    image = cv2.imread(file)\n",
        "\n",
        "    #converting image into gray scale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # converting it to binary image by Thresholding\n",
        "    # this step is require if you have colored image because if you skip this part \n",
        "    # then tesseract won't able to detect text correctly and this will give incorrect result\n",
        "    threshold_img = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
        "\n",
        "    # configuring parameters for tesseract and pandas\n",
        "    custom_config = r'--oem 3 --psm 6'\n",
        "    pandas_config = {'quoting': csv.QUOTE_NONE, 'sep': '\\t'}\n",
        "\n",
        "    # now feeding image to tesseract\n",
        "    details = pytesseract.image_to_data(threshold_img, output_type=pytesseract.Output.DICT, config=custom_config)\n",
        "    print(details)\n",
        "\n",
        "    print('\\n')\n",
        "    # To detect labels, uncomment this lines (enable json file AUTHENTICATION in Google account)\n",
        "    # os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"drive/My Drive/Colab Notebooks/vjson.json\"\n",
        "    # client = vision.ImageAnnotatorClient()\n",
        "    # detect_labels()\n",
        "\n",
        "  print('\\n')\n",
        "  print('done ...')\n",
        "\n",
        "process_all_images('drive/My Drive/Colab Notebooks/')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Results from image: drive/My Drive/Colab Notebooks/images/100000047_P1_1.jpg \n",
            "\n",
            "Text data alignment in this file \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-8a9917014679>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m \u001b[0mprocess_all_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/My Drive/Colab Notebooks/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-8a9917014679>\u001b[0m in \u001b[0;36mprocess_all_images\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# now feeding image to tesseract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mdetails\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_to_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreshold_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpytesseract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetails\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    }
  ]
}